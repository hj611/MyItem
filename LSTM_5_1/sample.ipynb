{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchtext\n",
    "import torchtext.vocab as Vocab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train = pd.read_csv('E:/LSTM_5_1/train_2018_1_model_2.csv')\n",
    "\n",
    "dt = train['dt'].values\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, traindata, numstep, length):\n",
    "        self.serial_number = traindata['serial_number'].value_counts()\n",
    "        self.value = traindata.iloc[:, length:-1].values\n",
    "        max = np.max(self.value)\n",
    "        min = np.min(self.value)\n",
    "        scalar = max - min \n",
    "        self.datas = list(map(lambda x: x / scalar, self.value))\n",
    "        self.input = []\n",
    "        self.label = []\n",
    "        for diskname in self.serial_number.index.sort_values():\n",
    "            traindata_name = traindata[traindata.serial_number == diskname]\n",
    "            self.datalabel = traindata_name.loc[:, 'label'].values.tolist()\n",
    "            j = 0\n",
    "            while(j + numstep <= len(traindata_name)):\n",
    "                self.input.append(torch.Tensor(self.datas[j:j + numstep]))\n",
    "                self.label.append(torch.Tensor(self.datalabel[j:j + numstep]))\n",
    "                j = j + 7  \n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "    def __getitem__(self, idx):\n",
    "        #data = self.datas[idx].reshape(1, -1)\n",
    "        return self.input[idx], self.label[idx]\n",
    "train_data = pd.read_csv('E:/LSTM_5_1/train_2018_1_model_2.csv')\n",
    "train_set = MyData(train_data, 7, 6)\n",
    "train_iter = DataLoader(MyData(train_data, 7, 6), batch_size = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2049"
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "train_data['label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(1743.)"
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "source": [
    "num = 0\n",
    "for X, y in train_set:\n",
    "    num = num + y.sum()\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2049"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "datalabel = train_data.loc[:, 'label'].values.tolist()\n",
    "num = 0\n",
    "for i in datalabel:\n",
    "    num = num + i\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['disk_10421', 'disk_10590', 'disk_10707', 'disk_10893', 'disk_10969',\n       'disk_11708', 'disk_117473', 'disk_117550', 'disk_117635',\n       'disk_117717',\n       ...\n       'disk_9086', 'disk_9124', 'disk_9315', 'disk_9440', 'disk_9518',\n       'disk_9761', 'disk_9801', 'disk_9807', 'disk_9810', 'disk_9996'],\n      dtype='object', length=361)"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "serial_number = train_data['serial_number'].value_counts()\n",
    "serial_number_name = serial_number.index.sort_values()\n",
    "serial_number_name.tolist().sort()\n",
    "serial_number_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "diff_day          dt  fault_time  label serial_number  \\\n0       96.0  2018-01-17  2018-04-23      0    disk_10421   \n1       95.0  2018-01-18  2018-04-23      0    disk_10421   \n2       94.0  2018-01-19  2018-04-23      0    disk_10421   \n3       93.0  2018-01-20  2018-04-23      0    disk_10421   \n4       92.0  2018-01-21  2018-04-23      0    disk_10421   \n5       91.0  2018-01-22  2018-04-23      0    disk_10421   \n6       90.0  2018-01-23  2018-04-23      0    disk_10421   \n7       89.0  2018-01-24  2018-04-23      0    disk_10421   \n8       88.0  2018-01-25  2018-04-23      0    disk_10421   \n9       87.0  2018-01-26  2018-04-23      0    disk_10421   \n10      86.0  2018-01-27  2018-04-23      0    disk_10421   \n11      85.0  2018-01-28  2018-04-23      0    disk_10421   \n12      84.0  2018-01-29  2018-04-23      0    disk_10421   \n13      83.0  2018-01-30  2018-04-23      0    disk_10421   \n14      82.0  2018-01-31  2018-04-23      0    disk_10421   \n\n    smart_184_normalized  smart_187_normalized  smart_188_normalized  \\\n0                  100.0                 100.0                 100.0   \n1                  100.0                 100.0                 100.0   \n2                  100.0                 100.0                 100.0   \n3                  100.0                 100.0                 100.0   \n4                  100.0                 100.0                 100.0   \n5                  100.0                 100.0                 100.0   \n6                  100.0                 100.0                 100.0   \n7                  100.0                 100.0                 100.0   \n8                  100.0                 100.0                 100.0   \n9                  100.0                 100.0                 100.0   \n10                 100.0                 100.0                 100.0   \n11                 100.0                 100.0                 100.0   \n12                 100.0                 100.0                 100.0   \n13                 100.0                 100.0                 100.0   \n14                 100.0                 100.0                 100.0   \n\n    smart_190_normalized  smart_193_normalized  smart_194_normalized  \\\n0                   79.0                 100.0                  21.0   \n1                   79.0                 100.0                  21.0   \n2                   80.0                 100.0                  20.0   \n3                   79.0                 100.0                  21.0   \n4                   79.0                 100.0                  21.0   \n5                   79.0                 100.0                  21.0   \n6                   80.0                 100.0                  20.0   \n7                   80.0                 100.0                  20.0   \n8                   79.0                 100.0                  21.0   \n9                   79.0                 100.0                  21.0   \n10                  80.0                 100.0                  20.0   \n11                  80.0                 100.0                  20.0   \n12                  80.0                 100.0                  20.0   \n13                  80.0                 100.0                  20.0   \n14                  80.0                 100.0                  20.0   \n\n    smart_195_normalized  smart_197_normalized  smart_198_normalized  \\\n0                  100.0                 100.0                 100.0   \n1                  100.0                 100.0                 100.0   \n2                  100.0                 100.0                 100.0   \n3                  100.0                 100.0                 100.0   \n4                  100.0                 100.0                 100.0   \n5                  100.0                 100.0                 100.0   \n6                  100.0                 100.0                 100.0   \n7                  100.0                 100.0                 100.0   \n8                  100.0                 100.0                 100.0   \n9                  100.0                 100.0                 100.0   \n10                 100.0                 100.0                 100.0   \n11                 100.0                 100.0                 100.0   \n12                 100.0                 100.0                 100.0   \n13                 100.0                 100.0                 100.0   \n14                 100.0                 100.0                 100.0   \n\n    smart_1_normalized  smart_3_normalized  smart_5_normalized  \\\n0                100.0                85.0               100.0   \n1                100.0                85.0               100.0   \n2                100.0                85.0               100.0   \n3                100.0                85.0               100.0   \n4                100.0                85.0               100.0   \n5                100.0                85.0               100.0   \n6                100.0                85.0               100.0   \n7                100.0                85.0               100.0   \n8                100.0                85.0               100.0   \n9                100.0                85.0               100.0   \n10               100.0                85.0               100.0   \n11               100.0                85.0               100.0   \n12               100.0                85.0               100.0   \n13               100.0                85.0               100.0   \n14               100.0                85.0               100.0   \n\n    smart_7_normalized  smart_9_normalized  \n0                 69.0               100.0  \n1                 69.0               100.0  \n2                 69.0               100.0  \n3                 69.0               100.0  \n4                 69.0               100.0  \n5                 69.0               100.0  \n6                 69.0               100.0  \n7                 69.0               100.0  \n8                 69.0               100.0  \n9                 69.0               100.0  \n10                69.0               100.0  \n11                69.0               100.0  \n12                69.0               100.0  \n13                69.0               100.0  \n14                69.0               100.0  \n15\n"
    }
   ],
   "source": [
    "serial_number = train_data['serial_number'].value_counts()\n",
    "for i in serial_number.index.sort_values():\n",
    "    print(train_data[train_data.serial_number == i])\n",
    "    print(len(train_data[train_data.serial_number == i]))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lenOfserial_number = []\n",
    "for days in serial_number.index.sort_values():\n",
    "    lenOfserial_number.append(len(train_data[train_data.serial_number == days]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(1743.)"
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "input = []\n",
    "label = []\n",
    "numstep = 7\n",
    "for diskname in serial_number.index:\n",
    "    j = 0\n",
    "    train_data_name = train_data[train_data.serial_number == diskname]\n",
    "    datalabel = train_data_name.loc[:, 'label'].values.tolist()\n",
    "    while(j + numstep <= len(train_data[train_data.serial_number == diskname])):\n",
    "        label.append(torch.Tensor(datalabel[j:j + numstep]))\n",
    "        j = j + 7  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8701"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "a = []\n",
    "for X, y in train_set:\n",
    "    for i in y:\n",
    "        a.append(i)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9798"
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "target train 0/1: 900/100\nbatch index 0, 0/1: 45/55\nbatch index 1, 0/1: 44/56\nbatch index 2, 0/1: 52/48\nbatch index 3, 0/1: 50/50\nbatch index 4, 0/1: 57/43\nbatch index 5, 0/1: 41/59\nbatch index 6, 0/1: 55/45\nbatch index 7, 0/1: 46/54\nbatch index 8, 0/1: 48/52\nbatch index 9, 0/1: 48/52\n"
    }
   ],
   "source": [
    "numDataPoints = 1000\n",
    "data_dim = 5\n",
    "bs = 100\n",
    "\n",
    "# Create dummy data with class imbalance 9 to 1\n",
    "data = torch.FloatTensor(numDataPoints, data_dim)\n",
    "target = np.hstack((np.zeros(int(numDataPoints * 0.9), dtype=np.int32),\n",
    "                    np.ones(int(numDataPoints * 0.1), dtype=np.int32)))\n",
    "\n",
    "print('target train 0/1: {}/{}'.format(\n",
    "    len(np.where(target == 0)[0]), len(np.where(target == 1)[0])))\n",
    "\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weight = samples_weight.double()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "target = torch.from_numpy(target).long()\n",
    "train_dataset = torch.utils.data.TensorDataset(data, target)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=bs, num_workers=1, sampler=sampler)\n",
    "\n",
    "for i, (data, target) in enumerate(train_loader):\n",
    "    print (\"batch index {}, 0/1: {}/{}\".format(\n",
    "        i,\n",
    "        len(np.where(target.numpy() == 0)[0]),\n",
    "        len(np.where(target.numpy() == 1)[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sample_count = np.array(\n",
    "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weight = samples_weight.double()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[56, 44]"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    " [len(np.where(target == t)[0]) for t in np.unique(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n(array([ 1,  2,  6,  7,  8,  9, 11, 12, 16, 17, 18, 21, 22, 23, 24, 25, 29,\n       30, 34, 36, 37, 39, 40, 42, 44, 46, 48, 49, 50, 53, 59, 61, 63, 64,\n       65, 66, 68, 69, 70, 73, 76, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88,\n       92, 93, 94, 95, 96], dtype=int64),)\n<class 'tuple'>\n1\n(array([ 0,  3,  4,  5, 10, 13, 14, 15, 19, 20, 26, 27, 28, 31, 32, 33, 35,\n       38, 41, 43, 45, 47, 51, 52, 54, 55, 56, 57, 58, 60, 62, 67, 71, 72,\n       74, 75, 79, 86, 89, 90, 91, 97, 98, 99], dtype=int64),)\n<class 'tuple'>\n"
    }
   ],
   "source": [
    "for t in np.unique(target):\n",
    "    print(t)\n",
    "    print(np.where(target == t))\n",
    "    print(type(np.where(target == t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n56\n<class 'numpy.ndarray'>\n1\n44\n<class 'numpy.ndarray'>\n"
    }
   ],
   "source": [
    "for t in np.unique(target):\n",
    "    print(t)\n",
    "    print(len(np.where(target == t)[0]))\n",
    "    print(type(np.where(target == t)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([56, 44])"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "class_sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n        0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n        0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n        0, 1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0.0227, 0.0179, 0.0179, 0.0227, 0.0227, 0.0227, 0.0179, 0.0179, 0.0179,\n        0.0179, 0.0227, 0.0179, 0.0179, 0.0227, 0.0227, 0.0227, 0.0179, 0.0179,\n        0.0179, 0.0227, 0.0227, 0.0179, 0.0179, 0.0179, 0.0179, 0.0179, 0.0227,\n        0.0227, 0.0227, 0.0179, 0.0179, 0.0227, 0.0227, 0.0227, 0.0179, 0.0227,\n        0.0179, 0.0179, 0.0227, 0.0179, 0.0179, 0.0227, 0.0179, 0.0227, 0.0179,\n        0.0227, 0.0179, 0.0227, 0.0179, 0.0179, 0.0179, 0.0227, 0.0227, 0.0179,\n        0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0179, 0.0227, 0.0179, 0.0227,\n        0.0179, 0.0179, 0.0179, 0.0179, 0.0227, 0.0179, 0.0179, 0.0179, 0.0227,\n        0.0227, 0.0179, 0.0227, 0.0227, 0.0179, 0.0179, 0.0179, 0.0227, 0.0179,\n        0.0179, 0.0179, 0.0179, 0.0179, 0.0179, 0.0227, 0.0179, 0.0179, 0.0227,\n        0.0227, 0.0227, 0.0179, 0.0179, 0.0179, 0.0179, 0.0179, 0.0227, 0.0227,\n        0.0227], dtype=torch.float64)"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "samples_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.01785714, 0.02272727])"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n        0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n        0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n        1, 1, 0, 1])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(np.where(target == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(1)\n0.01\ntensor(0)\n0.0011111111111111111\ntensor(1)\n0.01\n"
    }
   ],
   "source": [
    "for t in target:\n",
    "    print(t)\n",
    "    print(weight[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.00111111, 0.01      ])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyData(train_data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(0.)"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "num = 0\n",
    "for X, y in train_set:\n",
    "    num = num + y.sum()\n",
    "num      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 1], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "train_data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "58"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "train_data['label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 1], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "np.unique(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1000])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "samples_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitpytorchconda2fbdfbc796624a3f9e5f3a1ef21132b8",
   "display_name": "Python 3.8.3 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}