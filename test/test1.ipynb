{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('pytorch': conda)",
   "display_name": "Python 3.7.9 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "be203ce0b3afc4f5c37fbac412025d7ed1d67cabe9dd00b1fc8774c6d6d19d70"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "Ndata = pd.read_csv('E:/blackblaze/NegativeSample.csv')D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pdata = pd.read_csv('E:/blackblaze/positiveSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Ndata.sort_values(by = 'serial_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[0:50000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by = ['date', 'serial_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Unnamed: 0  capacity_bytes        date  failure        model  \\\n0               0   4000787030016  2018-01-01        0  ST4000DM000   \n31931       31931   4000787030016  2018-01-02        0  ST4000DM000   \n\n      serial_number  smart_190_raw  smart_193_raw  smart_194_raw  smart_1_raw  \\\n0          S3000A9T           22.0        64132.0           22.0   38941024.0   \n31931      S3000A9T           23.0        64132.0           23.0  204125824.0   \n\n       smart_241_raw  smart_7_raw  \n0       1.106223e+10  173472387.0  \n31931   1.107356e+10  174237590.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>capacity_bytes</th>\n      <th>date</th>\n      <th>failure</th>\n      <th>model</th>\n      <th>serial_number</th>\n      <th>smart_190_raw</th>\n      <th>smart_193_raw</th>\n      <th>smart_194_raw</th>\n      <th>smart_1_raw</th>\n      <th>smart_241_raw</th>\n      <th>smart_7_raw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4000787030016</td>\n      <td>2018-01-01</td>\n      <td>0</td>\n      <td>ST4000DM000</td>\n      <td>S3000A9T</td>\n      <td>22.0</td>\n      <td>64132.0</td>\n      <td>22.0</td>\n      <td>38941024.0</td>\n      <td>1.106223e+10</td>\n      <td>173472387.0</td>\n    </tr>\n    <tr>\n      <th>31931</th>\n      <td>31931</td>\n      <td>4000787030016</td>\n      <td>2018-01-02</td>\n      <td>0</td>\n      <td>ST4000DM000</td>\n      <td>S3000A9T</td>\n      <td>23.0</td>\n      <td>64132.0</td>\n      <td>23.0</td>\n      <td>204125824.0</td>\n      <td>1.107356e+10</td>\n      <td>174237590.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data[data.serial_number == 'S3000A9T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydata(Dataset):\n",
    "    def __init__(self, PositiveSample, NegativeSample, numstep):\n",
    "        self.serial_numberOfPositive = list(PositiveSample['serial_number'].value_counts().index)\n",
    "        self.serial_numberOfNegative = list(NegativeSample['serial_number'].value_counts().index)\n",
    "\n",
    "        self.PositiveSample_fea = PositiveSample.iloc[:, 6:12]\n",
    "        self.NegativeSample_fea = NegativeSample.iloc[:, 6:12]\n",
    "\n",
    "        self.colOfPositive = self.PositiveSample_fea.columns\n",
    "        self.colOfNegative = self.PositiveSample_fea.columns\n",
    "\n",
    "        self.fea_num = 6\n",
    "\n",
    "        self.X_som = []\n",
    "        self.y_smo = []\n",
    "        '''\n",
    "\n",
    "        for i in self.colOfPositive:\n",
    "            max = np.max(PositiveSample[i])\n",
    "            min = np.min(PositiveSample[i])\n",
    "            scalar = max - min \n",
    "            PositiveSample[i] = PositiveSample[i] / scalar\n",
    "        \n",
    "        for i in self.colOfNegative:\n",
    "            max = np.max(NegativeSample[i])\n",
    "            min = np.min(NegativeSample[i])\n",
    "            scalar = max - min \n",
    "            NegativeSample[i] = NegativeSample[i] / scalar\n",
    "        '''\n",
    "\n",
    "        for i in self.colOfPositive:\n",
    "            mean = np.mean(PositiveSample[i])\n",
    "            std = np.std(PositiveSample[i])\n",
    "            PositiveSample[i] = (PositiveSample[i] - mean) / std\n",
    "\n",
    "\n",
    "        for i in self.colOfNegative:\n",
    "            mean = np.mean(NegativeSample[i]\n",
    "            std = np.std(NegativeSample[i])\n",
    "            NegativeSample[i] = (NegativeSample[i] - mean) / std\n",
    "\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.inputs_som = []\n",
    "        self.labels_som = []\n",
    "\n",
    "\n",
    "        for i in self.serial_numberOfPositive:\n",
    "            Positive_bySerial = PositiveSample[PositiveSample['serial_number'] == i].iloc[:, 6: 12].values\n",
    "            for j in range(len(Positive_bySerial) - numstep):\n",
    "                self.inputs.append(torch.Tensor(np.array(Positive_bySerial[j: j + numstep])))\n",
    "                self.labels.append(torch.ones(1))\n",
    "\n",
    "        for i in self.serial_numberOfNegative:\n",
    "            Negetive_bySerial = NegativeSample[NegativeSample['serial_number'] == i].iloc[:, 6: 12].values\n",
    "            for j in range(len(Negetive_bySerial) - numstep):\n",
    "                self.inputs.append(torch.Tensor(np.array(Negetive_bySerial[j: j + numstep])))\n",
    "                self.labels.append(torch.zeros(1))\n",
    "        \n",
    "        for i in range(len(self.inputs)):\n",
    "            self.inputs[i] = np.array(self.inputs[i].reshape(numstep * self.fea_num))\n",
    "        \n",
    "        self.X_som, self.y_smo = SMOTE(random_state=42).fit_sample(self.inputs, self.labels)\n",
    "\n",
    "        for i in self.X_som:\n",
    "            i = torch.Tensor(i)\n",
    "            self.inputs_som.append(i.reshape(5, 6))\n",
    "\n",
    "        for i in self.y_smo:\n",
    "            if(i == 1):\n",
    "                self.labels_som.append(torch.ones(1))\n",
    "            else:\n",
    "                self.labels_som.append(torch.zeros(1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_som)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs_som[idx], self.labels_som[idx]\n",
    "\n",
    "    def get(self):\n",
    "        return self.inputs_som, self.labels_som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PositiveSample = Pdata\n",
    "NegativeSample = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Mydata(PositiveSample, NegativeSample, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = train_set.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = inputs\n",
    "labels2 = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(inputs2)):\n",
    "    inputs2[i] = np.array(inputs2[i].reshape(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smo = SMOTE(random_state=42)\n",
    "X_smo, y_smo = smo.fit_sample(inputs2, labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({1.0: 48939, 0.0: 48939})"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "Counter(y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs3 = []\n",
    "labels3 = []\n",
    "for i in X_smo:\n",
    "    i = torch.Tensor(i)\n",
    "    inputs3.append(i.reshape(5, 6))\n",
    "for i in y_smo:\n",
    "    labels3.append(torch.Tensor(int(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Tensor"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "type(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_set, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 0.3372, -0.6699,  0.3372,  1.6957, -1.4575, -0.0253],\n         [ 0.2162, -0.6699,  0.2162, -0.6394, -1.4580, -0.0253],\n         [ 0.2162, -0.6699,  0.2162,  1.2561, -1.4575, -0.0253],\n         [ 0.2162, -0.6699,  0.2162,  0.1570, -1.4573, -0.0253],\n         [ 0.1898, -0.6699,  0.1898,  0.4434, -1.4567, -0.0253]],\n\n        [[-0.6071, -0.4330, -0.6071,  0.1462, -0.6541, -0.0252],\n         [-0.4939, -0.4329, -0.4939,  0.5924, -0.6539, -0.0252],\n         [-0.6071, -0.4330, -0.6071, -1.0112, -0.6533, -0.0252],\n         [-0.5729, -0.4330, -0.5729,  0.7767, -0.6537, -0.0252],\n         [-0.5387, -0.4330, -0.5387,  0.2340, -0.6536, -0.0252]],\n\n        [[ 1.6478, -0.5148,  1.6478, -0.1483,  1.1076, -0.0253],\n         [ 1.5594, -0.5148,  1.5594,  1.5332,  1.1093, -0.0253],\n         [ 1.6775, -0.5148,  1.6775,  0.5425,  1.1106, -0.0253],\n         [ 1.5594, -0.5148,  1.5594, -0.0772,  1.1119, -0.0253],\n         [ 1.5594, -0.5147,  1.5594, -0.3794,  1.1131, -0.0253]],\n\n        ...,\n\n        [[-1.1977,  0.0390, -1.1977, -0.2146,  0.2723,  1.2282],\n         [-1.1977,  0.0390, -1.1977, -0.2146,  0.2723,  1.2282],\n         [-1.1977,  0.0390, -1.1977, -0.2146,  0.2723,  1.2282],\n         [-1.1977,  0.0390, -1.1977, -0.2146,  0.2723,  1.2282],\n         [-1.1977,  0.0390, -1.1977, -0.2146,  0.2723,  1.2282]],\n\n        [[-0.2059, -0.2929, -0.2059,  1.2000, -0.9271, -0.0253],\n         [-0.2642, -0.2929, -0.2642, -0.1716, -0.9266, -0.0253],\n         [-0.2950, -0.2929, -0.2950,  0.1885, -0.9265, -0.0253],\n         [-0.3533, -0.2929, -0.3533,  0.9673, -0.9261, -0.0253],\n         [-0.2642, -0.2929, -0.2642, -1.4167, -0.9277, -0.0253]],\n\n        [[ 0.2919, -0.5383,  0.2919, -0.6618, -1.0615, -0.7431],\n         [ 0.2919, -0.5383,  0.2919, -0.2324, -1.0614, -0.7422],\n         [ 0.5401, -0.5383,  0.5401, -0.7099, -1.0613, -0.7408],\n         [ 0.5401, -0.5383,  0.5401, -0.8741, -1.0612, -0.7395],\n         [ 0.5401, -0.5383,  0.5401, -0.9274, -1.0611, -0.7381]]])\ntorch.Size([64, 1])\n"
    }
   ],
   "source": [
    "i = 0\n",
    "for X, y in train_iter:\n",
    "    print(X)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "97878"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "97878"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.7637, -0.6067,  0.7637,  0.6392,  0.2936, -0.0252],\n        [ 0.7637, -0.6067,  0.7637,  1.3676,  0.2924, -0.0252],\n        [ 0.6164, -0.6067,  0.6164, -1.1836,  0.2910, -0.0252],\n        [ 0.7637, -0.6067,  0.7637,  1.3528,  0.2898, -0.0252],\n        [ 0.6164, -0.6067,  0.6164, -1.1616,  0.2878, -0.0252]])"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\ntraining start\nepoch 1, loss 0.0437, train acc 32.479, time 18.2 sec\nepoch 2, loss 0.0398, train acc 32.516, time 17.6 sec\nepoch 3, loss 0.0091, train acc 32.490, time 17.4 sec\nepoch 4, loss 0.0046, train acc 32.479, time 17.8 sec\nepoch 5, loss 0.0111, train acc 32.531, time 17.7 sec\nepoch 6, loss 0.0274, train acc 32.494, time 17.9 sec\nepoch 7, loss 0.0140, train acc 32.467, time 18.1 sec\nepoch 8, loss 0.0115, train acc 32.462, time 17.9 sec\nepoch 9, loss 0.0186, train acc 32.513, time 18.3 sec\nepoch 10, loss 0.0280, train acc 32.516, time 18.2 sec\n"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "class diskLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(diskLSTM, self).__init__()\n",
    "\n",
    "        self.LSTM_1 = nn.LSTM(input_size=6, hidden_size=32, batch_first=True)\n",
    "        self.LSTM_2 = nn.LSTM(input_size=32, hidden_size=64, batch_first=True)\n",
    "        self.LSTM_3 = nn.LSTM(input_size=64, hidden_size=128, batch_first=True)\n",
    " \n",
    "        self.linear_1 = nn.Linear(128, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        X, _ = self.LSTM_1(X, state)\n",
    "        X, _ = self.LSTM_2(X, state)\n",
    "        X, _ = self.LSTM_3(X, state)\n",
    "\n",
    "        X = X[:, X.size(1) - 1, :]\n",
    "\n",
    "\n",
    "        X = self.linear_1(X)\n",
    "\n",
    "        X = F.tanh(X)\n",
    "        X = self.linear_2(X)\n",
    "\n",
    "        X = F.tanh(X)\n",
    "        X = self.linear_3(X)\n",
    "\n",
    "        X = torch.sigmoid(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "class Mydata(Dataset):\n",
    "    def __init__(self, PositiveSample, NegativeSample, numstep):\n",
    "        self.serial_numberOfPositive = list(PositiveSample['serial_number'].value_counts().index)\n",
    "        self.serial_numberOfNegative = list(NegativeSample['serial_number'].value_counts().index)\n",
    "\n",
    "        self.PositiveSample_fea = PositiveSample.iloc[:, 6:12]\n",
    "        self.NegativeSample_fea = NegativeSample.iloc[:, 6:12]\n",
    "\n",
    "        self.colOfPositive = self.PositiveSample_fea.columns\n",
    "        self.colOfNegative = self.PositiveSample_fea.columns\n",
    "\n",
    "        self.fea_num = 6\n",
    "\n",
    "        self.X_som = []\n",
    "        self.y_smo = []\n",
    "        '''\n",
    "\n",
    "        for i in self.colOfPositive:\n",
    "            max = np.max(PositiveSample[i])\n",
    "            min = np.min(PositiveSample[i])\n",
    "            scalar = max - min \n",
    "            PositiveSample[i] = PositiveSample[i] / scalar\n",
    "        \n",
    "        for i in self.colOfNegative:\n",
    "            max = np.max(NegativeSample[i])\n",
    "            min = np.min(NegativeSample[i])\n",
    "            scalar = max - min \n",
    "            NegativeSample[i] = NegativeSample[i] / scalar\n",
    "        '''\n",
    "\n",
    "        for i in self.colOfPositive:\n",
    "            mean = np.mean(PositiveSample[i])\n",
    "            std = np.std(PositiveSample[i])\n",
    "            PositiveSample[i] = (PositiveSample[i] - mean) / std\n",
    "\n",
    "\n",
    "        for i in self.colOfNegative:\n",
    "            mean = np.mean(NegativeSample[i])\n",
    "            std = np.std(NegativeSample[i])\n",
    "            NegativeSample[i] = (NegativeSample[i] - mean) / std\n",
    "\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.inputs_som = []\n",
    "        self.labels_som = []\n",
    "\n",
    "\n",
    "        for i in self.serial_numberOfPositive:\n",
    "            Positive_bySerial = PositiveSample[PositiveSample['serial_number'] == i].iloc[:, 6: 12].values\n",
    "            for j in range(len(Positive_bySerial) - numstep):\n",
    "                self.inputs.append(torch.Tensor(np.array(Positive_bySerial[j: j + numstep])))\n",
    "                self.labels.append(torch.ones(1))\n",
    "\n",
    "        for i in self.serial_numberOfNegative:\n",
    "            Negetive_bySerial = NegativeSample[NegativeSample['serial_number'] == i].iloc[:, 6: 12].values\n",
    "            for j in range(len(Negetive_bySerial) - numstep):\n",
    "                self.inputs.append(torch.Tensor(np.array(Negetive_bySerial[j: j + numstep])))\n",
    "                self.labels.append(torch.zeros(1))\n",
    "        \n",
    "        for i in range(len(self.inputs)):\n",
    "            self.inputs[i] = np.array(self.inputs[i].reshape(numstep * self.fea_num))\n",
    "        \n",
    "        self.X_som, self.y_smo = SMOTE(random_state=42).fit_sample(self.inputs, self.labels)\n",
    "\n",
    "        for i in self.X_som:\n",
    "            i = torch.Tensor(i)\n",
    "            self.inputs_som.append(i.reshape(5, 6))\n",
    "\n",
    "        for i in self.y_smo:\n",
    "            if(i == 1):\n",
    "                self.labels_som.append(torch.ones(1))\n",
    "            else:\n",
    "                self.labels_som.append(torch.zeros(1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_som)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs_som[idx], self.labels_som[idx]\n",
    "\n",
    "    def get(self):\n",
    "        return self.inputs_som, self.labels_som\n",
    "\n",
    "def classifyRes(y_hat):\n",
    "    for i in range(y_hat.size(0)):\n",
    "        if(y_hat[i] > 0.5):\n",
    "            y_hat[i] = 1\n",
    "        else:\n",
    "            y_hat[i] = 0\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def train(net, train_iter, optimizer, num_epochs):\n",
    "    print(\"training start\")\n",
    "    loss = torch.nn.BCELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        state = None\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.squeeze(1)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X.float(), state)\n",
    "            y_hat = y_hat.to(device)\n",
    "            l = loss(y_hat, y.float())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            y_hat = classifyRes(y_hat)\n",
    "            train_acc_sum += (y_hat == y).sum().item()\n",
    "            n += y.size(0)\n",
    "            batch_count += 1\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, time %.1f sec'\n",
    "        % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, time.time() - start))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PositiveSample = Pdata\n",
    "NegativeSample = data\n",
    "\n",
    "train_set = Mydata(PositiveSample, NegativeSample, 5)\n",
    "train_iter = DataLoader(train_set, batch_size = 64, shuffle = True)\n",
    "\n",
    "\n",
    "net = diskLSTM()\n",
    "net = net.to(device)\n",
    "lr, num_epochs = 0.01, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "train(net, train_iter, optimizer, num_epochs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smo = SMOTE(random_state=42)\n",
    "a = []\n",
    "b = []\n",
    "a.append(np.arange(30))\n",
    "a.append(np.arange(30))\n",
    "b.append(0)\n",
    "b.append(1)\n",
    "A, B = smo.fit_sample(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(30,)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_set.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "438"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([438.])"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;Quadro P400&#39;"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type=&#39;cuda&#39;)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([64, 2])"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.5000, 0.5000])\n"
    }
   ],
   "source": [
    "for a in x:\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-4-64bd7041c41e&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----&gt; 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--&gt; 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren&#39;t as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that &#39;&#39;.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--&gt; 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         &quot;&quot;&quot;\n\u001b[1;32m--&gt; 179\u001b[1;33m         raise TypeError(f&#39;Object of type {o.__class__.__name__} &#39;\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f&#39;is not JSON serializable&#39;)\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "l.append(torch.ones(1))\n",
    "a = json.dumps(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " obj={'mat':torch.randn(10, 10),'name': '10','test':{'entry':1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(l, 'E:/blackblaze/a.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.load('E:/blackblaze/a.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "list"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-27-effc14818ce9&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[1;32m----&gt; 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train_set.__getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "                           weights=[0.9, 0.1], n_informative=3, \n",
    "                           n_redundant=1, flip_y=0,\n",
    "                           n_features=20, n_clusters_per_class=1, \n",
    "                           n_samples=1000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.60013068, -1.42766402, -0.8128431 ,  0.18619638, -0.44607171,\n        1.46153788, -0.20792618, -0.12137372, -0.06446773, -1.33101647,\n       -1.66919399, -0.13944961,  0.03095361, -0.51795082, -0.42962235,\n       -0.45009542,  2.30385329, -0.55302378,  0.14876985, -1.74795877])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in y:\n",
    "    l.append(i)\n",
    "a = []\n",
    "for i in X:\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(20,)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({0: 900, 1: 100})\n"
    }
   ],
   "source": [
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "smo = SMOTE(random_state=42)\n",
    "X_smo, y_smo = smo.fit_sample(a, l)"
   ]
  },
  {
   "source": [
    "type(X_smo[0])"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "list"
     },
     "metadata": {},
     "execution_count": 35
    }
   ]
  },
  {
   "source": [
    "Counter(y_smo)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument &#39;ratio&#39;",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-12-4bd9fd240c69&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[1;32m----&gt; 1\u001b[1;33m \u001b[0msmo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_smo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_smo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_smo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m                           FutureWarning)\n\u001b[0;32m    639\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 640\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument &#39;ratio&#39;"
     ]
    }
   ],
   "source": [
    "smo = SMOTE(ratio={1: 300},random_state=42)\n",
    "X_smo, y_smo = smo.fit_sample(X, y)\n",
    "print(Counter(y_smo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({0: 900, 1: 900})\n"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# 同理，也可使用ratio来指定下采样的比例\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_rus, y_rus = rus.fit_sample(X, y)\n",
    "print(Counter(y_smo))\n",
    "# Counter({0: 500, 1: 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "X_adam y_ada = ADASYN().fit_sample(X, y)\n",
    "print(Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5, 6)\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected &lt;= 2.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-36-7784fec0b59f&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[1;32m----&gt; 1\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMydata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPositiveSample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNegativeSample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m&lt;ipython-input-10-11928f69eb87&gt;\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, PositiveSample, NegativeSample, numstep)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0msmo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 113\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 77\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         X, y = self._validate_data(\n\u001b[1;32m--&gt; 135\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         )\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse=&#39;csr&#39;, force_all_finite=True,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m&gt;=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             raise ValueError(&quot;Found array with dim %d. %s expected &lt;= 2.&quot;\n\u001b[1;32m--&gt; 641\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected &lt;= 2."
     ]
    }
   ],
   "source": [
    "train_set = Mydata(PositiveSample, NegativeSample, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}