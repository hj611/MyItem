{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('pytorch': conda)",
   "display_name": "Python 3.7.9 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "be203ce0b3afc4f5c37fbac412025d7ed1d67cabe9dd00b1fc8774c6d6d19d70"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.load('E:/blackblaze/inputs.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "160993"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.load('E:/blackblaze/labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "160993"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_som = []\n",
    "labels_som = []\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    inputs[i] = np.array(inputs[i].reshape(5 * 6))\n",
    "\n",
    "X_som, y_smo = SMOTE(random_state=42).fit_sample(inputs, labels)\n",
    "\n",
    "for i in X_som:\n",
    "    i = torch.Tensor(i)\n",
    "    inputs_som.append(i.reshape(5, 6))\n",
    "\n",
    "for i in y_smo:\n",
    "    if(i == 1):\n",
    "        labels_som.append(torch.ones(1))\n",
    "    else:\n",
    "        labels_som.append(torch.zeros(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "321110"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(inputs_som)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({1.0: 160555, 0.0: 160555})"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "Counter(y_smo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n",
      "training start\n",
      "y tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 1., 0.], device='cuda:0')\n",
      "y_hat tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "fp:  0.0\n",
      "sum_fp:  33.0\n",
      "epoch 1, loss 0.6983, train acc 31.000, time 0.1 sec, fp acc 0.000\n",
      "y tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 1., 0.], device='cuda:0')\n",
      "y_hat tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "fp:  39.0\n",
      "sum_fp:  39.0\n",
      "epoch 2, loss 0.6702, train acc 39.000, time 0.1 sec, fp acc 1.000\n",
      "y tensor([1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 1., 0., 1.], device='cuda:0')\n",
      "y_hat tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "fp:  0.0\n",
      "sum_fp:  32.0\n",
      "epoch 3, loss 3.3331, train acc 32.000, time 0.1 sec, fp acc 0.000\n",
      "y tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 1., 1., 0.], device='cuda:0')\n",
      "y_hat tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "fp:  0.0\n",
      "sum_fp:  29.0\n",
      "epoch 4, loss 1.2217, train acc 35.000, time 0.1 sec, fp acc 0.000\n",
      "y tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0.], device='cuda:0')\n",
      "y_hat tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "fp:  37.0\n",
      "sum_fp:  37.0\n",
      "epoch 5, loss 1.0779, train acc 37.000, time 0.1 sec, fp acc 1.000\n",
      "y tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 0., 0.], device='cuda:0')\n",
      "y_hat tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "fp:  34.0\n",
      "sum_fp:  34.0\n",
      "epoch 6, loss 2.0169, train acc 34.000, time 0.1 sec, fp acc 1.000\n",
      "y tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')\n",
      "y_hat tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "fp:  32.0\n",
      "sum_fp:  32.0\n",
      "epoch 7, loss 1.9387, train acc 32.000, time 0.1 sec, fp acc 1.000\n",
      "y tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0')\n",
      "y_hat tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "fp:  24.0\n",
      "sum_fp:  24.0\n",
      "epoch 8, loss 1.3121, train acc 24.000, time 0.1 sec, fp acc 1.000\n",
      "y tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1.], device='cuda:0')\n",
      "y_hat tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "fp:  0.0\n",
      "sum_fp:  36.0\n",
      "epoch 9, loss 0.9173, train acc 28.000, time 0.1 sec, fp acc 0.000\n",
      "y tensor([1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 1., 1.], device='cuda:0')\n",
      "y_hat tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "fp:  0.0\n",
      "sum_fp:  33.0\n",
      "epoch 10, loss 1.5003, train acc 31.000, time 0.1 sec, fp acc 0.000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(device)\n",
    "\n",
    "class diskLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(diskLSTM, self).__init__()\n",
    "\n",
    "        self.LSTM_1 = nn.LSTM(input_size=6, hidden_size=32, batch_first=True)\n",
    "        self.LSTM_2 = nn.LSTM(input_size=32, hidden_size=64, batch_first=True)\n",
    "        self.LSTM_3 = nn.LSTM(input_size=64, hidden_size=128, batch_first=True)\n",
    " \n",
    "        self.linear_1 = nn.Linear(128, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        X, _ = self.LSTM_1(X, state)\n",
    "        X, _ = self.LSTM_2(X, state)\n",
    "        X, _ = self.LSTM_3(X, state)\n",
    "\n",
    "        X = X[:, X.size(1) - 1, :]\n",
    "\n",
    "\n",
    "        X = self.linear_1(X)\n",
    "\n",
    "        X = torch.tanh(X)\n",
    "        X = self.linear_2(X)\n",
    "\n",
    "        X = torch.tanh(X)\n",
    "        X = self.linear_3(X)\n",
    "\n",
    "        X = torch.sigmoid(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "class Mydata(Dataset):\n",
    "    def __init__(self, inputs, labels, numstep):\n",
    "\n",
    "        self.fea_num = 6\n",
    "\n",
    "        self.X_som = []\n",
    "        self.y_smo = []\n",
    "\n",
    "        \n",
    "        self.inputs_som = []\n",
    "        self.labels_som = []\n",
    "\n",
    "  \n",
    "        for i in range(len(inputs)):\n",
    "            inputs[i] = np.array(inputs[i].reshape(numstep * self.fea_num))\n",
    "        \n",
    "        self.X_som, self.y_smo = SMOTE(random_state=42).fit_sample(inputs, labels)\n",
    "\n",
    "        for i in self.X_som:\n",
    "            i = torch.Tensor(i)\n",
    "            self.inputs_som.append(i.reshape(numstep, self.fea_num))\n",
    "\n",
    "        for i in self.y_smo:\n",
    "            if(i == 1):\n",
    "                self.labels_som.append(torch.ones(1))\n",
    "            else:\n",
    "                self.labels_som.append(torch.zeros(1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_som)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs_som[idx], self.labels_som[idx]\n",
    "\n",
    "    def get(self):\n",
    "        return self.inputs_som, self.labels_som\n",
    "\n",
    "def classifyRes(y_hat):\n",
    "    for i in range(y_hat.size(0)):\n",
    "        if(y_hat[i] > 0.5):\n",
    "            y_hat[i] = 1\n",
    "        else:\n",
    "            y_hat[i] = 0\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def train(net, train_iter, optimizer, num_epochs):\n",
    "    print(\"training start\")\n",
    "    loss = torch.nn.BCELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start, fp, sum_f = 0.0, 0.0, 0, 0, time.time(), 0.0, 0.0\n",
    "        state = None\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.squeeze(1)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X.float(), state)\n",
    "            y_hat = y_hat.to(device)\n",
    "            l = loss(y_hat, y.float())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            y_hat = classifyRes(y_hat)\n",
    "            train_acc_sum += (y_hat.cuda() == y).sum().item()\n",
    "            n += y.size(0)\n",
    "            batch_count += 1\n",
    "            for i in range(len(y_hat)):\n",
    "                if(y[i] == 1 and y[i] == y_hat[i]):\n",
    "                    fp = fp + 1\n",
    "            sum_f = sum_f + y.sum().item()\n",
    "            print('y', y)\n",
    "            print('y_hat', y_hat.reshape(y_hat.size(0)))\n",
    "            print('fp: ', fp)\n",
    "            print('sum_fp: ', sum_f)\n",
    "            break\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, time %.1f sec, fp acc %.3f'\n",
    "        % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, time.time() - start, fp / sum_f))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set = Mydata(inputs, labels, 5)\n",
    "train_iter = DataLoader(train_set, batch_size = 64, shuffle = True)\n",
    "\n",
    "\n",
    "net = diskLSTM()\n",
    "net = net.to(device)\n",
    "lr, num_epochs = 0.1, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "train(net, train_iter, optimizer, num_epochs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.genfromtxt('E:/blackblaze/positiveSample.csv', dtype = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([b&#39;,capacity_bytes,date,failure,model,serial_number,smart_190_raw,smart_193_raw,smart_194_raw,smart_1_raw,smart_241_raw,smart_7_raw&#39;,\n       b&#39;0,4.00079E+12,2018/1/1,0,ST4000DM000,W3004X68,17,103203,17,216941544,18981102610,304428807&#39;,\n       b&#39;1,4.00079E+12,2018/1/2,0,ST4000DM000,W3004X68,17,103203,17,88620216,18983249064,305190394&#39;,\n       ...,\n       b&#39;2645,4.00079E+12,2018/9/27,0,ST4000DM000,S300ZRQS,23,6899,23,162741008,48646632335,261367389&#39;,\n       b&#39;2646,4.00079E+12,2018/9/28,0,ST4000DM000,S300ZRQS,23,6901,23,159964192,48666406967,263100937&#39;,\n       b&#39;2647,4.00079E+12,2018/9/29,1,ST4000DM000,S300ZRQS,23,6901,23,191744272,48676237535,264091278&#39;],\n      dtype=&#39;|S128&#39;)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "numpy.bytes_"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "type(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0, 1, 1, 0])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1, 1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for i in range(len(a)):\n",
    "    if(a[i] == 1 and a[i] == b[i]):\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "int"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "type(a.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ae0c534ae842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiskLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-ae0c534ae842>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from torch.autograd import Variable\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "print(device)\n",
    "\n",
    "class diskLSTM(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(diskLSTM, self).__init__()\n",
    "\n",
    "        self.LSTM_1 = nn.LSTM(input_size=6, hidden_size=32, batch_first=True)\n",
    "        self.LSTM_2 = nn.LSTM(input_size=32, hidden_size=64, batch_first=True)\n",
    "        self.LSTM_3 = nn.LSTM(input_size=64, hidden_size=128, batch_first=True)\n",
    " \n",
    "        self.linear_1 = nn.Linear(128, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.state_1 = (Variable(torch.randn(1, batch_size, 32).cuda()), Variable(torch.randn(1, batch_size, 32).cuda()))\n",
    "        self.state_2 = (Variable(torch.randn(1, batch_size, 64).cuda()), Variable(torch.randn(1, batch_size, 64).cuda()))\n",
    "        self.state_3 = (Variable(torch.randn(1, batch_size, 128).cuda()), Variable(torch.randn(1, batch_size, 128).cuda()))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X, _ = self.LSTM_1(X, self.state_1)\n",
    "        X, _ = self.LSTM_2(X, self.state_2)\n",
    "        X, _ = self.LSTM_3(X, self.state_3)\n",
    "\n",
    "        X = X[:, X.size(1) - 1, :]\n",
    "\n",
    "\n",
    "        X = self.linear_1(X)\n",
    "\n",
    "        X = torch.tanh(X)\n",
    "        X = self.linear_2(X)\n",
    "\n",
    "        X = torch.tanh(X)\n",
    "        X = self.linear_3(X)\n",
    "\n",
    "        X = torch.sigmoid(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "class Mydata(Dataset):\n",
    "    def __init__(self, inputs, labels, numstep):\n",
    "\n",
    "        self.fea_num = 6\n",
    "\n",
    "        self.X_som = []\n",
    "        self.y_smo = []\n",
    "\n",
    "        \n",
    "        self.inputs_som = []\n",
    "        self.labels_som = []\n",
    "\n",
    "  \n",
    "        for i in range(len(inputs)):\n",
    "            inputs[i] = np.array(inputs[i].reshape(numstep * self.fea_num))\n",
    "        \n",
    "        self.X_som, self.y_smo = SMOTE(random_state=42).fit_sample(inputs, labels)\n",
    "\n",
    "        for i in self.X_som:\n",
    "            i = torch.Tensor(i)\n",
    "            self.inputs_som.append(i.reshape(numstep, self.fea_num))\n",
    "\n",
    "        for i in self.y_smo:\n",
    "            if(i == 1):\n",
    "                self.labels_som.append(torch.ones(1))\n",
    "            else:\n",
    "                self.labels_som.append(torch.zeros(1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_som)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs_som[idx], self.labels_som[idx]\n",
    "\n",
    "    def get(self):\n",
    "        return self.inputs_som, self.labels_som\n",
    "\n",
    "def classifyRes(y_hat):\n",
    "    for i in range(y_hat.size(0)):\n",
    "        if(y_hat[i] > 0.5):\n",
    "            y_hat[i] = 1\n",
    "        else:\n",
    "            y_hat[i] = 0\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def train(net, train_iter, optimizer, num_epochs):\n",
    "    print(\"training start\")\n",
    "    loss = torch.nn.BCELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start, sum_fp, fp = 0.0, 0.0, 0, 0, time.time(), 0.0, 0.0\n",
    "        print('strat sum_fp: ', sum_fp)\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.squeeze(1)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X.float())\n",
    "            y_hat = y_hat.reshape(y_hat.size(0))\n",
    "            print('strat y_hat', y_hat)\n",
    "            y_hat = y_hat.to(device)\n",
    "            l = loss(y_hat, y.float())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            y_hat = classifyRes(y_hat)\n",
    "            train_acc_sum += (y_hat.cuda() == y).sum().item()\n",
    "            n += y.size(0)\n",
    "            batch_count += 1\n",
    "            for i in range(len(y_hat)):\n",
    "                if(y[i] == 1 and y[i] == y_hat[i]):\n",
    "                    fp = fp + 1\n",
    "            sum_fp = sum_fp + y.sum().item()\n",
    "            print(y.shape)\n",
    "            print('y ', y)\n",
    "            print('y_hat', y_hat)\n",
    "            print(y_hat.shape)\n",
    "            print('fp: ', fp)\n",
    "            print('sum_fp: ', sum_fp)\n",
    "            print('*'*20)\n",
    "            break\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, FP acc %.3f, time %.1f sec'\n",
    "        % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, fp / sum_fp, time.time() - start))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set = Mydata(inputs, labels, 5)\n",
    "train_iter = DataLoader(train_set, batch_size = 64, shuffle = True, drop_last=True)\n",
    "\n",
    "\n",
    "net = diskLSTM(64)\n",
    "net = net.to(device)\n",
    "lr, num_epochs = 0.001, 100\n",
    "optimizer = torch.optim.Adamax(net.parameters(), lr=lr)\n",
    "print('lr', lr)\n",
    "train(net, train_iter, optimizer, num_epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}